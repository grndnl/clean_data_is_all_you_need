{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "from dla_pipeline_support_functions import load_mask_registry\n",
    "\n",
    "from transformers import (\n",
    "    LayoutLMv3FeatureExtractor,\n",
    "    LayoutLMv3Tokenizer,\n",
    "    LayoutLMv3Processor,\n",
    "    LayoutLMv3ForTokenClassification,\n",
    ")\n",
    "import json\n",
    "import torch\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "from PIL.JpegImagePlugin import JpegImageFile\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 999)\n",
    "pd.set_option(\"display.max_columns\", 999)\n",
    "pd.set_option(\"display.width\", 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"/data\"):\n",
    "    os.symlink(\"/user/w210/clean_data_is_all_you_need/app/data\", \"/data\")\n",
    "\n",
    "DATA_DIRECTORY = \"/data\"\n",
    "\n",
    "S1_INPUT_PDFS_DIR = join(DATA_DIRECTORY, \"s1_input_pdfs\")\n",
    "S2_DLA_INPUTS_DIR = join(DATA_DIRECTORY, \"s2_dla_inputs\")\n",
    "S3_OUTPUTS_DIR = join(DATA_DIRECTORY, \"s3_outputs\")\n",
    "S4_JSON_TEXT_OUTPUTS_DIR = join(DATA_DIRECTORY, \"s4_json_text_output\")\n",
    "PAGE_MASK_DIR = join(S3_OUTPUTS_DIR, \"page_masks\")\n",
    "\n",
    "PRETRAINED_MODEL_DIR = \"/user/w210/large_file_repo/models_pretrained\"\n",
    "MODEL_TAG = \"layoutlmv3-finetuned-DocLayNet_large_sci_23_12_02-15_50_34/checkpoint-5946\"\n",
    "MODEL_WEIGHTS = join(PRETRAINED_MODEL_DIR, MODEL_TAG)\n",
    "MODEL_PROCESSOR = join(PRETRAINED_MODEL_DIR, \"microsoft-layoutlmv3-base-processor\")\n",
    "MODEL_CATEGORIES_JSON = join(DATA_DIRECTORY, \"dla_categories_doclaynet.json\")\n",
    "\n",
    "GLOBAL_BATCH_SIZE = 1\n",
    "MAX_LENGTH = 512\n",
    "\n",
    "for pth in [\n",
    "    DATA_DIRECTORY,\n",
    "    S1_INPUT_PDFS_DIR,\n",
    "    S2_DLA_INPUTS_DIR,\n",
    "    S3_OUTPUTS_DIR,\n",
    "    S4_JSON_TEXT_OUTPUTS_DIR,\n",
    "    PAGE_MASK_DIR,\n",
    "    MODEL_WEIGHTS,\n",
    "    MODEL_PROCESSOR,\n",
    "    MODEL_CATEGORIES_JSON,\n",
    "]:\n",
    "    assert os.path.exists(pth), f\"PATH NOT FOUND: {pth}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize box diamentions to range 0 to 1000\n",
    "def normalized_box(box, image_width, image_height):\n",
    "    return [\n",
    "        int(1000 * (box[0] / image_width)),\n",
    "        int(1000 * (box[1] / image_height)),\n",
    "        int(1000 * (box[2] / image_width)),\n",
    "        int(1000 * (box[3] / image_height)),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_registry = load_mask_registry(PAGE_MASK_DIR, validate_csvs=False)\n",
    "mask_registry[\"umask_id\"] = np.arange(len(mask_registry))\n",
    "mask_registry[\"new_category\"] = np.full(len(mask_registry), -1)\n",
    "mask_registry[\"new_category_lbl\"] = \"Unkown\"\n",
    "\n",
    "page_image_registry = pd.read_csv(join(S3_OUTPUTS_DIR, \"page_images_list.csv\"))\n",
    "\n",
    "doc_text_registry = pd.read_csv(join(S4_JSON_TEXT_OUTPUTS_DIR, \"text_extract.csv\"))\n",
    "\n",
    "doc_text_registry[\"json_path\"] = doc_text_registry.apply(\n",
    "    lambda var: var[\"pdf_file\"].replace(\".pdf\", \".json\"),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "print(mask_registry.columns)\n",
    "print(\"\")\n",
    "print(page_image_registry.columns)\n",
    "print(\"\")\n",
    "print(doc_text_registry.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_doclaylet_dataset(\n",
    "    page_image_registry: pd.DataFrame,\n",
    "    doc_text_registry: pd.DataFrame,\n",
    "    mask_registry: pd.DataFrame,\n",
    "    max_text_length: int,\n",
    "):\n",
    "    normalized_bbox_page_dict_list = []\n",
    "\n",
    "    dataset_dict = {\n",
    "        \"document_id\": [],\n",
    "        \"page_no\": [],\n",
    "        \"images\": [],\n",
    "        \"original_img_shape\": [],\n",
    "        \"words\": [],\n",
    "        \"bboxes\": [],\n",
    "        \"normalized_bboxes\": [],\n",
    "        \"umask_id\": [],\n",
    "        \"dummy_label\": [],\n",
    "    }\n",
    "    for i, row in doc_text_registry.iterrows():\n",
    "        # DOCUMENT SPECIFIC VALUES ########################################\n",
    "        ###################################################################\n",
    "\n",
    "        doc_id = row[\"pdf_file\"]\n",
    "\n",
    "        doc_json_path = join(row[\"output_directory\"], row[\"json_path\"])\n",
    "        with open(doc_json_path, \"r\") as json_file:\n",
    "            doc_json = json.load(json_file)\n",
    "\n",
    "        doc_json_df = pd.DataFrame(doc_json[\"paper_text\"])\n",
    "\n",
    "        # Ensure the box is read as numbers\n",
    "        doc_json_df[\"section_im_bbox\"] = doc_json_df[\"section_im_bbox\"].apply(\n",
    "            lambda var: literal_eval(str(var))\n",
    "        )\n",
    "        doc_json_df.sort_values(by=[\"section_page\", \"section_id\"], inplace=True)\n",
    "\n",
    "        # PAGE SPECIFIC VALUES ############################################\n",
    "        ###################################################################\n",
    "        doc_image_df = page_image_registry.query(f\"document=='{doc_id}'\")\n",
    "\n",
    "        for ii, im_row in doc_image_df.iterrows():\n",
    "            page_no = im_row[\"page_no\"]\n",
    "\n",
    "            # Dataset Doc Info\n",
    "            dataset_dict[\"document_id\"].append(doc_id)\n",
    "            dataset_dict[\"page_no\"].append(page_no)\n",
    "\n",
    "            # Dataset Images\n",
    "            page_img_path = join(S2_DLA_INPUTS_DIR, im_row[\"file_name\"])\n",
    "            page_img = JpegImageFile(page_img_path)\n",
    "            dataset_dict[\"original_img_shape\"].append(page_img.size)\n",
    "\n",
    "            image_width, image_height = page_img.size\n",
    "            dataset_dict[\"images\"].append(page_img)\n",
    "\n",
    "            # MASK SPECIFIC VALUES ########################################\n",
    "            ###############################################################\n",
    "\n",
    "            doc_page_json_df = doc_json_df.query(f\"section_page=={page_no}\")\n",
    "            doc_page_json_df[\"mask_id\"] = doc_page_json_df[\"section_id\"]\n",
    "\n",
    "            # Dataset Words\n",
    "            #   NOTE: We need to ensure that per page there are less tokens\n",
    "            #   generated than the maximum number of tokens allowed. The code\n",
    "            #   below, ensures that each section gets tokens.\n",
    "\n",
    "            page_text = doc_page_json_df[\"section_text\"].to_list()\n",
    "\n",
    "            no_masks = len(page_text)\n",
    "            words_per_mask = int((max_text_length / no_masks) * 0.60)\n",
    "\n",
    "            short_page_text = []\n",
    "            for section_text in page_text:\n",
    "                short_txt = section_text.split(\" \")[0:words_per_mask]\n",
    "                short_txt = \" \".join(short_txt)\n",
    "                short_page_text.append(short_txt)\n",
    "\n",
    "            dataset_dict[\"words\"].append(short_page_text)\n",
    "\n",
    "            # Dataset bboxes\n",
    "            bboxes = doc_page_json_df[\"section_im_bbox\"].to_list()\n",
    "\n",
    "            normalized_bboxes = [\n",
    "                normalized_box(bboxs, image_width, image_height) for bboxs in bboxes\n",
    "            ]\n",
    "\n",
    "            dataset_dict[\"bboxes\"].append(bboxes)\n",
    "\n",
    "            dataset_dict[\"normalized_bboxes\"].append(normalized_bboxes)\n",
    "\n",
    "            # Unique Mask ID:\n",
    "            page_mask_df = mask_registry.query(\n",
    "                f\"document=='{doc_id}' & page_no=={page_no}\"\n",
    "            )\n",
    "            page_mask_df = pd.merge(\n",
    "                doc_page_json_df, page_mask_df, on=\"mask_id\", how=\"inner\"\n",
    "            )\n",
    "            umask_ids = page_mask_df[\"umask_id\"].to_list()\n",
    "\n",
    "            assert len(short_page_text) == len(bboxes) == len(umask_ids)\n",
    "\n",
    "            dataset_dict[\"umask_id\"].append(umask_ids)\n",
    "            dataset_dict[\"dummy_label\"].append(np.zeros(len(umask_ids)))\n",
    "\n",
    "            normalized_bbox_page_dict = {}\n",
    "\n",
    "            for umask_id, n_bbox in zip(umask_ids, normalized_bboxes):\n",
    "                normalized_bbox_page_dict[tuple(n_bbox)] = umask_id\n",
    "\n",
    "            normalized_bbox_page_dict_list.append(normalized_bbox_page_dict)\n",
    "\n",
    "    return Dataset.from_dict(dataset_dict), dataset_dict, normalized_bbox_page_dict_list\n",
    "\n",
    "\n",
    "dataset, dataset_dict, normalized_bbox_page_dict_list = generate_doclaylet_dataset(\n",
    "    page_image_registry, doc_text_registry, mask_registry, max_text_length=MAX_LENGTH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(MODEL_CATEGORIES_JSON, \"r\") as json_file:\n",
    "    categories_dict = json.load(json_file)\n",
    "\n",
    "categories_dict\n",
    "\n",
    "id2label = {int(k): v for k, v in categories_dict.items()}\n",
    "label2id = {v: int(k) for k, v in categories_dict.items()}\n",
    "\n",
    "print(id2label)\n",
    "print(label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model and Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "processor = LayoutLMv3Processor.from_pretrained(MODEL_PROCESSOR, apply_ocr=False)\n",
    "model = LayoutLMv3ForTokenClassification.from_pretrained(\n",
    "    MODEL_WEIGHTS, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = dataset_dict[\"images\"][idx]\n",
    "texts_list = dataset_dict[\"words\"][idx]\n",
    "normalized_bboxes = dataset_dict[\"normalized_bboxes\"][idx]\n",
    "\n",
    "encoding = processor(\n",
    "    img,\n",
    "    texts_list,\n",
    "    boxes=normalized_bboxes,\n",
    "    truncation=True,\n",
    "    stride=128,\n",
    "    padding=\"max_length\",\n",
    "    max_length=MAX_LENGTH,\n",
    "    return_overflowing_tokens=True,\n",
    "    return_offsets_mapping=True,\n",
    ")\n",
    "\n",
    "offset_mapping = encoding.pop(\"offset_mapping\")\n",
    "\n",
    "overflow_to_sample_mapping = encoding.pop(\"overflow_to_sample_mapping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the shape of input_ids\n",
    "\n",
    "x = []\n",
    "for i in range(0, len(encoding[\"input_ids\"])):\n",
    "    x.append(torch.tensor(encoding[\"input_ids\"][i]))\n",
    "x = torch.stack(x)\n",
    "encoding[\"input_ids\"] = x\n",
    "\n",
    "# change the shape of pixel values\n",
    "\n",
    "x = []\n",
    "for i in range(0, len(encoding[\"pixel_values\"])):\n",
    "    x.append(torch.from_numpy(encoding[\"pixel_values\"][i]))\n",
    "x = torch.stack(x)\n",
    "encoding[\"pixel_values\"] = x\n",
    "\n",
    "x = []\n",
    "for i in range(0, len(encoding[\"attention_mask\"])):\n",
    "    x.append(torch.tensor(encoding[\"attention_mask\"][i]))\n",
    "x = torch.stack(x)\n",
    "encoding[\"attention_mask\"] = x\n",
    "\n",
    "# change the shape of bbox\n",
    "x = []\n",
    "for i in range(0, len(encoding[\"bbox\"])):\n",
    "    x.append(torch.tensor(encoding[\"bbox\"][i]))\n",
    "x = torch.stack(x)\n",
    "encoding[\"bbox\"] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in encoding.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = outputs.logits\n",
    "\n",
    "predictions = logits.argmax(-1).squeeze().tolist()\n",
    "token_boxes = encoding.bbox.squeeze().tolist()\n",
    "\n",
    "if len(token_boxes) == 512:\n",
    "    predictions = [predictions]\n",
    "    token_boxes = [token_boxes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "predictions = list(itertools.chain(*predictions))\n",
    "token_boxes = list(itertools.chain(*token_boxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logit_scores_from_predictions(scores, predictions):\n",
    "    return scores[np.arange(len(predictions)), predictions]\n",
    "\n",
    "\n",
    "def logit_to_prob(logit):\n",
    "    odds = np.exp(logit)\n",
    "    prob = odds / (1 + odds)\n",
    "    return prob\n",
    "\n",
    "\n",
    "logit_to_prob_vect = np.vectorize(logit_to_prob)\n",
    "\n",
    "\n",
    "logits_all_cats = logits.squeeze()\n",
    "\n",
    "\n",
    "prediction_logits = get_logit_scores_from_predictions(logits_all_cats, predictions)\n",
    "prediction_scores = logit_to_prob_vect(prediction_logits.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnormalize_box(bbox, width, height):\n",
    "    # print(bbox)\n",
    "    return [\n",
    "        width * (bbox[0] / 1000),\n",
    "        height * (bbox[1] / 1000),\n",
    "        width * (bbox[2] / 1000),\n",
    "        height * (bbox[3] / 1000),\n",
    "    ]\n",
    "\n",
    "\n",
    "width, height = img.size\n",
    "print(width, height)\n",
    "true_predictions = [model.config.id2label[pred] for pred in predictions]\n",
    "true_boxes = [unnormalize_box(box, width, height) for box in token_boxes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageDraw, ImageFont\n",
    "\n",
    "draw = ImageDraw.Draw(img)\n",
    "\n",
    "font = ImageFont.load_default()\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "label2color = {\n",
    "    \"Table\": \"blue\",\n",
    "    \"Section-header\": \"blue\",\n",
    "    \"Caption\": \"blue\",\n",
    "    \"Text\": \"blue\",\n",
    "    \"Picture\": \"blue\",\n",
    "    \"List-item\": \"blue\",\n",
    "    \"Page-footer\": \"blue\",\n",
    "    \"Title\": \"blue\",\n",
    "    \"Page-header\": \"blue\",\n",
    "    \"Footnote\": \"blue\",\n",
    "    \"Formula\": \"blue\",\n",
    "}\n",
    "\n",
    "for predicted_label, box in zip(true_predictions, true_boxes):\n",
    "    draw.rectangle(box, outline=label2color[predicted_label])\n",
    "    draw.text(\n",
    "        (box[0] + 10, box[1] - 10),\n",
    "        text=predicted_label,\n",
    "        fill=label2color[predicted_label],\n",
    "        font=font,\n",
    "    )\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_dict = {}\n",
    "prediction_score_dict = {}\n",
    "\n",
    "for prediction, prediction_scr, token_bx in zip(\n",
    "    predictions, prediction_scores, token_boxes\n",
    "):\n",
    "    token_bx_tup = tuple(token_bx)\n",
    "\n",
    "    # if token_bx_tup in prediction_dict.keys():\n",
    "    #     if prediction_dict[token_bx_tup] != prediction:\n",
    "    #         print(\"error\")\n",
    "    # else:\n",
    "    #     prediction_dict[token_bx_tup] = prediction\n",
    "\n",
    "    if token_bx_tup not in prediction_dict.keys():\n",
    "        prediction_dict[token_bx_tup] = []\n",
    "        prediction_score_dict[token_bx_tup] = []\n",
    "\n",
    "    prediction_dict[token_bx_tup].append(prediction)\n",
    "    prediction_score_dict[token_bx_tup].append(prediction_scr)\n",
    "\n",
    "prediction_dict, prediction_score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token_bx in prediction_dict.keys():\n",
    "    pred_array = prediction_dict[token_bx]\n",
    "    pred_score_array = prediction_score_dict[token_bx]\n",
    "\n",
    "    cats = np.zeros(len(label2id)).tolist()\n",
    "\n",
    "    for i in range(len(pred_array)):\n",
    "        i_c = pred_array[i]\n",
    "        cats[i_c] += pred_score_array[i]\n",
    "\n",
    "    cats = np.array(cats)\n",
    "\n",
    "    cats = cats / (i + 1)\n",
    "\n",
    "    most_common_value = np.argmax(cats)\n",
    "\n",
    "    prediction_dict[token_bx] = most_common_value\n",
    "    prediction_score_dict[token_bx] = cats[most_common_value]\n",
    "\n",
    "    # unique_values, counts = np.unique(pred_array, return_counts=True)\n",
    "\n",
    "    # # Find the index of the maximum count\n",
    "    # most_common_index = np.argmax(counts)\n",
    "\n",
    "    # # Get the most commonly repeated value\n",
    "    # most_common_value = unique_values[most_common_index]\n",
    "\n",
    "    # prediction_dict[token_bx] = most_common_value\n",
    "\n",
    "    # # Note, this function only takes the most common value and not\n",
    "    # # the score.  We should use the score as well.\n",
    "\n",
    "\n",
    "prediction_dict, prediction_score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_bbox_page_dict = normalized_bbox_page_dict_list[idx]\n",
    "for box_tup, pred in prediction_dict.items():\n",
    "    if box_tup in normalized_bbox_page_dict.keys():\n",
    "        umask_id = normalized_bbox_page_dict[box_tup]\n",
    "\n",
    "        matching_index = mask_registry.index[\n",
    "            mask_registry[\"umask_id\"] == umask_id\n",
    "        ].tolist()[0]\n",
    "\n",
    "        mask_registry.at[matching_index, \"new_category\"] = pred\n",
    "        mask_registry.at[matching_index, \"new_category_lbl\"] = id2label[pred]\n",
    "\n",
    "\n",
    "mask_registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "layoutlmv3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
