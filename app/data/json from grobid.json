{
    "paper_id": "1503",
    "header": {
        "generated_with": "S2ORC 1.0.0",
        "date_generated": "2023-10-17T20:01:23.708905Z"
    },
    "title": "Robustly Leveraging Prior Knowledge in Text Classification",
    "authors": [
        {
            "first": "Biao",
            "middle": [],
            "last": "Liu",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "Tsinghua University Haidian District",
                "location": {
                    "settlement": "Beijing",
                    "country": "China"
                }
            },
            "email": ""
        },
        {
            "first": "Minlie",
            "middle": [],
            "last": "Huang",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "Tsinghua University Haidian District",
                "location": {
                    "settlement": "Beijing",
                    "country": "China"
                }
            },
            "email": "aihuang@tsinghua.edu.cn"
        }
    ],
    "year": "",
    "venue": null,
    "identifiers": {},
    "abstract": "Prior knowledge has been shown very useful to address many natural language processing tasks. Many approaches have been proposed to formalise a variety of knowledge, however, whether the proposed approach is robust or sensitive to the knowledge supplied to the model has rarely been discussed. In this paper, we propose three regularization terms on top of generalized expectation criteria, and conduct extensive experiments to justify the robustness of the proposed methods. Experimental results demonstrate that our proposed methods obtain remarkable improvements and are much more robust than baselines.",
    "pdf_parse": {
        "paper_id": "1503",
        "_pdf_hash": "",
        "abstract": [
            {
                "text": "Prior knowledge has been shown very useful to address many natural language processing tasks. Many approaches have been proposed to formalise a variety of knowledge, however, whether the proposed approach is robust or sensitive to the knowledge supplied to the model has rarely been discussed. In this paper, we propose three regularization terms on top of generalized expectation criteria, and conduct extensive experiments to justify the robustness of the proposed methods. Experimental results demonstrate that our proposed methods obtain remarkable improvements and are much more robust than baselines.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Abstract",
                "sec_num": null
            }
        ],
        "body_text": [
            {
                "text": "We posses a wealth of prior knowledge about many natural language processing tasks. For example, in text categorization, we know that words such as NBA, player, and basketball are strong indicators of the sports category (Druck et al., 2008) , and words like terrible, boring, and messing indicate a negative polarity while words like perfect, exciting, and moving suggest a positive polarity in sentiment classification.",
                "cite_spans": [
                    {
                        "start": 221,
                        "end": 241,
                        "text": "(Druck et al., 2008)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "A key problem arisen here, is how to leverage such knowledge to guide the learning process, an interesting problem for both NLP and machine learning communities. Previous studies addressing the problem fall into several lines. First, to leverage prior knowledge to label data (Haghighi and Klein, 2006; Raghavan and Allan, 2007) . Second, to encode prior knowledge with a prior on parameters, which can be commonly seen in many Bayesian approaches (Andrzejewski and Zhu, 2009; Andrzejewski et al., 2011) . Third, to formalise prior knowledge with additional variables and dependencies (Li et al., 2010) . Last, to use prior knowledge to control the distributions over latent output variables (Grac \u00b8a et al., 2007; McCallum et al., 2007; Chang et al., 2007) , which makes the output variables easily interpretable.",
                "cite_spans": [
                    {
                        "start": 276,
                        "end": 302,
                        "text": "(Haghighi and Klein, 2006;",
                        "ref_id": "BIBREF18"
                    },
                    {
                        "start": 303,
                        "end": 328,
                        "text": "Raghavan and Allan, 2007)",
                        "ref_id": "BIBREF27"
                    },
                    {
                        "start": 448,
                        "end": 476,
                        "text": "(Andrzejewski and Zhu, 2009;",
                        "ref_id": "BIBREF2"
                    },
                    {
                        "start": 477,
                        "end": 503,
                        "text": "Andrzejewski et al., 2011)",
                        "ref_id": null
                    },
                    {
                        "start": 585,
                        "end": 602,
                        "text": "(Li et al., 2010)",
                        "ref_id": null
                    },
                    {
                        "start": 692,
                        "end": 714,
                        "text": "(Grac \u00b8a et al., 2007;",
                        "ref_id": null
                    },
                    {
                        "start": 715,
                        "end": 737,
                        "text": "McCallum et al., 2007;",
                        "ref_id": null
                    },
                    {
                        "start": 738,
                        "end": 757,
                        "text": "Chang et al., 2007)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "However, a crucial problem, which has rarely been addressed, is the bias in the prior knowledge that we supply to the learning model. Would the model be robust or sensitive to the prior knowledge? Or, which kind of knowledge is appropriate for the task? Let's see an example: we may be a baseball fan but unfamiliar with hockey so that we can provide a few number of feature words of baseball, but much less of hockey for a baseball-hockey classification task. Such prior knowledge may mislead the model with heavy bias to baseball. If the model cannot handle this situation appropriately, the performance may be undesirable.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "In this paper, we investigate into the problem in the framework of Generalized Expectation Criteria (McCallum et al., 2007) . The study aims to reveal the factors of reducing the sensibility of the prior knowledge and therefore to make the model more robust and practical. To this end, we introduce auxiliary regularization terms in which our prior knowledge is formalized as distribution over output variables. Recall the example just mentioned, though we do not have enough knowledge to provide features for class hockey, it is easy for us to provide some neutral words, namely words that are not strong in-dicators of any class, like player here. As one of the factors revealed in this paper, supplying neutral feature words can boost the performance remarkably, making the model more robust.",
                "cite_spans": [
                    {
                        "start": 100,
                        "end": 123,
                        "text": "(McCallum et al., 2007)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "More attractively, we do not need manual annotation to label these neutral feature words in our proposed approach.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "More specifically, we explore three regularization terms to address the problem: (1) a regularization term associated with neutral features; (2) the maximum entropy of class distribution regularization term; and (3) the KL divergence between reference and predicted class distribution. For the first manner, we simply use the most common features as neutral features and assume the neutral features are distributed uniformly over class labels. For the second and third one, we assume we have some knowledge about the class distribution which will be detailed soon later.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "To summarize, the main contributions of this work are as follows:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "\u2022 We explore three regularization terms to make the model more robust: a regularization term associated with neutral features, the maximum entropy of class distribution regularization term, and the KL divergence between reference and predicted class distribution.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "\u2022 Experiments demonstrate that the proposed approaches outperform baselines and work much more robustly.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "The rest of the paper is structured as follows: In Section 2, we briefly describe the generalized expectation criteria and present the proposed regularization terms. In Section 3, we conduct extensive experiments to justify the proposed methods. We survey related work in Section 4, and summarize our work in Section 5.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "We address the robustness problem on top of GE-FL (Druck et al., 2008) , a GE method which leverages labeled features as prior knowledge. A labeled feature is a strong indicator of a specific class and is manually provided to the classifier. For example, words like amazing, exciting can be labeled features for class positive in sentiment classification.",
                "cite_spans": [
                    {
                        "start": 50,
                        "end": 70,
                        "text": "(Druck et al., 2008)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Method",
                "sec_num": "2"
            },
            {
                "text": "Generalized expectation (GE) criteria (McCallum et al., 2007) provides us a natural way to directly constrain the model in the preferred direction. For example, when we know the proportion of each class of the dataset in a classification task, we can guide the model to predict out a pre-specified class distribution.",
                "cite_spans": [
                    {
                        "start": 38,
                        "end": 61,
                        "text": "(McCallum et al., 2007)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Generalized Expectation Criteria",
                "sec_num": "2.1"
            },
            {
                "text": "Formally, in a parameter estimation objective function, a GE term expresses preferences on the value of some constraint functions about the model's expectation. Given a constraint function G(x, y), a conditional model distribution p \u03b8 (y|x), an empirical distribution p(x) over input samples and a score function S, a GE term can be expressed as follows:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Generalized Expectation Criteria",
                "sec_num": "2.1"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "S(E p(x) [E p \u03b8 (y|x) [G(x, y)]])",
                        "eq_num": "(1)"
                    }
                ],
                "section": "Generalized Expectation Criteria",
                "sec_num": "2.1"
            },
            {
                "text": "2.2 Learning from Labeled Features Druck et al. (2008) proposed GE-FL to learn from labeled features using generalized expectation criteria. When given a set of labeled features K, the reference distribution over classes of these features is denoted by p(y|x k ), k \u2208 K. GE-FL introduces the divergence between this reference distribution and the model predicted distribution p \u03b8 (y|x k ) , as a term of the objective function:",
                "cite_spans": [
                    {
                        "start": 35,
                        "end": 54,
                        "text": "Druck et al. (2008)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Generalized Expectation Criteria",
                "sec_num": "2.1"
            },
            {
                "text": "O = k\u2208K KL(p(y|x k )||p \u03b8 (y|x k )) + y,i \u03b8 2 yi 2\u03c3 2 (2)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Generalized Expectation Criteria",
                "sec_num": "2.1"
            },
            {
                "text": "where \u03b8 yi is the model parameter which indicates the importance of word i to class y. The predicted distribution p \u03b8 (y|x k ) can be expressed as follows:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Generalized Expectation Criteria",
                "sec_num": "2.1"
            },
            {
                "text": "p \u03b8 (y|x k ) = 1 C k x p \u03b8 (y|x)I(x k ) in which I(x k ) is 1 if feature k occurs in instance",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Generalized Expectation Criteria",
                "sec_num": "2.1"
            },
            {
                "text": "x and 0 otherwise, C k = x I(x k ) is the number of instances with a non-zero value of feature k, and p \u03b8 (y|x) takes a softmax form as follows:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Generalized Expectation Criteria",
                "sec_num": "2.1"
            },
            {
                "text": "p \u03b8 (y|x) = 1 Z(x) exp( i \u03b8 yi x i ).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Generalized Expectation Criteria",
                "sec_num": "2.1"
            },
            {
                "text": "To solve the optimization problem, L-BFGS can be used for parameter estimation.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Generalized Expectation Criteria",
                "sec_num": "2.1"
            },
            {
                "text": "In the framework of GE, this term can be obtained by setting the constraint function G(x, y) = 1 C k I(y)I(x k ), where I(y) is an indicator vector with 1 at the index corresponding to label y and 0 elsewhere.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Generalized Expectation Criteria",
                "sec_num": "2.1"
            },
            {
                "text": "GE-FL reduces the heavy load of instance annotation and performs well when we provide prior knowledge with no bias. In our experiments, we observe that comparable numbers of labeled features for each class have to be supplied. But as mentioned before, it is often the case that we are not able to provide enough knowledge for some of the classes. For the baseball-hockey classification task, as shown before, GE-FL will predict most of the instances as baseball. In this section, we will show three terms to make the model more robust.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Regularization Terms",
                "sec_num": "2.3"
            },
            {
                "text": "Neutral features are features that are not informative indicator of any classes, for instance, word player to the baseball-hockey classification task. Such features are usually frequent words across all categories. When we set the preference distribution of the neutral features to be uniform distributed, these neutral features will prevent the model from biasing to the class that has a dominate number of labeled features.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Regularization Associated with Neutral Features",
                "sec_num": "2.3.1"
            },
            {
                "text": "Formally, given a set of neutral features K , the uniform distribution is pu (y|x k ) = 1 |C| , k \u2208 K , where |C| is the number of classes. The objective function with the new term becomes",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Regularization Associated with Neutral Features",
                "sec_num": "2.3.1"
            },
            {
                "text": "O N E = O + k\u2208K KL(p u (y|x k )||p \u03b8 (y|x k )). (3)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Regularization Associated with Neutral Features",
                "sec_num": "2.3.1"
            },
            {
                "text": "Note that we do not need manual annotation to provide neutral features. One simple way is to take the most common features as neutral features. Experimental results show that this strategy works successfully.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Regularization Associated with Neutral Features",
                "sec_num": "2.3.1"
            },
            {
                "text": "Another way to prevent the model from drifting from the desired direction is to constrain the predicted class distribution on unlabeled data. When lacking knowledge about the class distribution of the data, one feasible way is to take maximum entropy principle, as below:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Regularization with Maximum Entropy Principle",
                "sec_num": "2.3.2"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "O M E = O + \u03bb y p(y) log p(y)",
                        "eq_num": "(4)"
                    }
                ],
                "section": "Regularization with Maximum Entropy Principle",
                "sec_num": "2.3.2"
            },
            {
                "text": "where p(y) is the predicted class distribution, given by p(y) = 1",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Regularization with Maximum Entropy Principle",
                "sec_num": "2.3.2"
            },
            {
                "text": "x p \u03b8 (y|x). To control the influence of this term on the overall objective function, we can tune \u03bb according to the difference in the number of labeled features of each class. In this paper, we simply set \u03bb to be proportional to the total number of labeled features, say \u03bb = \u03b2|K|.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "|X|",
                "sec_num": null
            },
            {
                "text": "This maximum entropy term can be derived by setting the constraint function to G(x, y) = I(y). Therefore, E p \u03b8 (y|x) [G(x, y) ] is just the model distribution p \u03b8 (y|x) and its expectation with the empirical distribution p(x) is simply the average over input samples, namely p(y). When S takes the maximum entropy form, we can derive the objective function as above.",
                "cite_spans": [
                    {
                        "start": 118,
                        "end": 126,
                        "text": "[G(x, y)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "|X|",
                "sec_num": null
            },
            {
                "text": "Sometimes, we have already had much knowledge about the corpus, and can estimate the class distribution roughly without labeling instances. Therefore, we introduce the KL divergence between the predicted and reference class distributions into the objective function.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Regularization with KL Divergence",
                "sec_num": "2.3.3"
            },
            {
                "text": "Given the preference class distribution p(y), we modify the objective function as follows:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Regularization with KL Divergence",
                "sec_num": "2.3.3"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "O KL = O + \u03bbKL(p(y)||p(y))",
                        "eq_num": "(5)"
                    }
                ],
                "section": "Regularization with KL Divergence",
                "sec_num": "2.3.3"
            },
            {
                "text": "Similarly, we set \u03bb = \u03b2|K|. This divergence term can be derived by setting the constraint function to G(x, y) = I(y) and setting the score function to S(p, p) = i pi log pi p i , where p and p are distributions. Note that this regularization term involves the reference class distribution which will be discussed later.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Regularization with KL Divergence",
                "sec_num": "2.3.3"
            },
            {
                "text": "In this section, we first justify the approach when there exists unbalance in the number of labeled features or in class distribution. Then, to test the influence of \u03bb, we conduct some experiments with the method which incorporates the KL divergence of class distribution. Last, we evaluate our approaches in 9 commonly used text classification datasets. We set \u03bb = 5|K| by default in all experiments unless there is explicit declaration.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experiments",
                "sec_num": "3"
            },
            {
                "text": "The baseline we choose here is GE-FL (Druck et al., 2008) , a method based on generalization expectation criteria.",
                "cite_spans": [
                    {
                        "start": 37,
                        "end": 57,
                        "text": "(Druck et al., 2008)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experiments",
                "sec_num": "3"
            },
            {
                "text": "We evaluate our methods on several commonly used datasets whose themes range from sentiment, webpage, science to medical and healthcare. We use bag-of-words feature and remove stopwords in the preprocess stage. Though we have labels of all documents, we do not use them during the learning process, instead, we use the label of features.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Data Preparation",
                "sec_num": "3.1"
            },
            {
                "text": "The movie dataset, in which the task is to classify the movie reviews as positive or negtive, is used for testing the proposed approaches with unbalanced labeled features, unbalanced datasets or different \u03bb parameters 1 . All unbalanced datasets are constructed based on the movie dataset by randomly removing documents of the positive class. For each experiment, we conduct 10-fold cross validation.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Data Preparation",
                "sec_num": "3.1"
            },
            {
                "text": "As described in (Druck et al., 2008) , there are two ways to obtain labeled features. The first way is to use information gain. We first calculate the mutual information of all features according to the labels of the documents and select the top 20 as labeled features for each class as a feature pool. Note that using information gain requires the document label, but this is only to simulate how we human provide prior knowledge to the model. The second way is to use LDA (Blei et al., 2003) to select features. We use the same selection process as (Druck et al., 2008) , where they first train a LDA on the dataset, and then select the most probable features of each topic (sorted by P (w i |t j ), the probability of word w i given topic t j ).",
                "cite_spans": [
                    {
                        "start": 16,
                        "end": 36,
                        "text": "(Druck et al., 2008)",
                        "ref_id": null
                    },
                    {
                        "start": 474,
                        "end": 493,
                        "text": "(Blei et al., 2003)",
                        "ref_id": null
                    },
                    {
                        "start": 551,
                        "end": 571,
                        "text": "(Druck et al., 2008)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Labeled Features",
                "sec_num": null
            },
            {
                "text": "Similar to (Schapire et al., 2002; Druck et al., 2008) , we estimate the reference distribution of the labeled features using a heuristic strategy. If there are |C| classes in total, and n classes are associated with a feature k, the probability that feature k is related with any one of the n classes is 0.9 n and with 1 We also experimented on other datasets, and observed similar results.",
                "cite_spans": [
                    {
                        "start": 11,
                        "end": 34,
                        "text": "(Schapire et al., 2002;",
                        "ref_id": null
                    },
                    {
                        "start": 35,
                        "end": 54,
                        "text": "Druck et al., 2008)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Labeled Features",
                "sec_num": null
            },
            {
                "text": "any other class is 0.1",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Labeled Features",
                "sec_num": null
            },
            {
                "text": "|C|-n 2 .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Labeled Features",
                "sec_num": null
            },
            {
                "text": "Neutral features are the most frequent words after removing stop words, and their reference distributions are uniformly distributed. We use the top 10 frequent words as neutral features in all experiments.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Labeled Features",
                "sec_num": null
            },
            {
                "text": "In this section, we evaluate our approach when there is unbalanced knowledge on the categories to be classified. The labeled features are obtained through information gain. Two settings are chosen:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "With Unbalanced Labeled Features",
                "sec_num": "3.2"
            },
            {
                "text": "(a) We randomly select t \u2208 [1, 20] features from the feature pool for one class, and only one feature for the other. The original balanced movie dataset is used (positive:negative=1:1).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "With Unbalanced Labeled Features",
                "sec_num": "3.2"
            },
            {
                "text": "(b) Similar to (a), but the dataset is unbalanced, obtained by randomly removing 75% positive documents (positive:negative=1:4).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "With Unbalanced Labeled Features",
                "sec_num": "3.2"
            },
            {
                "text": "As shown in Figure 1 , Maximum entropy principle shows improvement only on the balanced case. An obvious reason is that maximum entropy only favors uniform distribution.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 19,
                        "end": 20,
                        "text": "1",
                        "ref_id": "FIGREF0"
                    }
                ],
                "eq_spans": [],
                "section": "With Unbalanced Labeled Features",
                "sec_num": "3.2"
            },
            {
                "text": "Incorporating Neutral features performs similarly to maximum entropy since we assume that neutral words are uniformly distributed. Its accuracy decreases slowly when the number of labeled features becomes larger (t > 4) (Figure 1(a) ), suggesting that the model gradually biases to the class with more labeled features, just like GE-FL.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 228,
                        "end": 232,
                        "text": "1(a)",
                        "ref_id": "FIGREF0"
                    }
                ],
                "eq_spans": [],
                "section": "With Unbalanced Labeled Features",
                "sec_num": "3.2"
            },
            {
                "text": "Incorporating the KL divergence of class distribution performs much better than GE-FL on both balanced and unbalanced datasets. This shows that it is effective to control the unbalance in labeled features and in the dataset.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "With Unbalanced Labeled Features",
                "sec_num": "3.2"
            },
            {
                "text": "We also compare with the baseline when the labeled features are balanced. Similar to the experiment above, the labeled features are obtained by information gain. Two settings are experimented with:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "With Balanced Labeled Features",
                "sec_num": "3.3"
            },
            {
                "text": "(a) We randomly select t \u2208 [1, 20] features from the feature pool for each class, and conduct comparisons on the original balanced movie dataset (positive:negtive=1:1). Results are shown in Figure 2 . When the dataset is balanced (Figure 2(a) ), there is little difference between GE-FL and our methods. The reason is that the proposed regularization terms provide no additional knowledge to the model and there is no bias in the labeled features. On the unbalanced dataset (Figure 2(b)), incorporating KL divergence is much better than GE-FL since we provide additional knowledge(the true class distribution), but maximum entropy and neutral features are much worse because forcing the model to approach the uniform distribu-tion misleads it.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 197,
                        "end": 198,
                        "text": "2",
                        "ref_id": "FIGREF1"
                    },
                    {
                        "start": 238,
                        "end": 242,
                        "text": "2(a)",
                        "ref_id": "FIGREF1"
                    }
                ],
                "eq_spans": [],
                "section": "With Balanced Labeled Features",
                "sec_num": "3.3"
            },
            {
                "text": "Our methods are also evaluated on datasets with different unbalanced class distributions. We manually construct several movie datasets with class distributions of 1:2, 1:3, 1:4 by randomly removing 50%, 67%, 75% positive documents. The original balanced movie dataset is used as a control group. We test with both balanced and unbalanced labeled features. For the balanced case, we randomly select 10 features from the feature pool for each class, and for the unbalanced case, we select 10 features for one class, and 1 feature for the other. Results are shown in Figure 3 .",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 571,
                        "end": 572,
                        "text": "3",
                        "ref_id": "FIGREF3"
                    }
                ],
                "eq_spans": [],
                "section": "With Unbalanced Class Distributions",
                "sec_num": "3.4"
            },
            {
                "text": "Figure 3 (a) shows that when the dataset and the labeled features are both balanced, there is little difference between our methods and GE-FL(also see Figure 2(a) ). But when the class distribution becomes more unbalanced, the difference becomes more remarkable. Performance of neutral features and maximum entropy decrease significantly but incorporating KL divergence increases remarkably. This suggests if we have more accurate knowledge about class distribution, KL divergence can guide the model to the right direction.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 7,
                        "end": 8,
                        "text": "3",
                        "ref_id": "FIGREF3"
                    },
                    {
                        "start": 158,
                        "end": 162,
                        "text": "2(a)",
                        "ref_id": "FIGREF1"
                    }
                ],
                "eq_spans": [],
                "section": "With Unbalanced Class Distributions",
                "sec_num": "3.4"
            },
            {
                "text": "Figure 3 (b) shows that when the labeled features are unbalanced, our methods significantly outper-forms GE-FL. Incorporating KL divergence is robust enough to control unbalance both in the dataset and in labeled features while the other three methods are not so competitive.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 7,
                        "end": 12,
                        "text": "3 (b)",
                        "ref_id": "FIGREF3"
                    }
                ],
                "eq_spans": [],
                "section": "With Unbalanced Class Distributions",
                "sec_num": "3.4"
            },
            {
                "text": "We present the influence of \u03bb on the method that incorporates KL divergence in this section. Since we simply set \u03bb = \u03b2|K|, we just tune \u03b2 here. Note that when \u03b2 = 0, the newly introduced regularization term is disappeared, and thus the model is actually GE-FL. Again, we test the method with different \u03bb in two settings:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "The Influence of \u03bb",
                "sec_num": "3.5"
            },
            {
                "text": "(a) the feature pool for one class, and only one feature for the other class. The original balanced movie dataset is used (positive:negative=1:1).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "The Influence of \u03bb",
                "sec_num": "3.5"
            },
            {
                "text": "(b) Similar to (a), but the dataset is unbalanced, obtained by randomly removing 75% positive documents (positive:negative=1:4).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "The Influence of \u03bb",
                "sec_num": "3.5"
            },
            {
                "text": "Results are shown in Figure 4 . As expected, \u03bb reflects how strong the regularization is. The model tends to be closer to our preferences with the increasing of \u03bb on both cases.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 28,
                        "end": 29,
                        "text": "4",
                        "ref_id": "FIGREF4"
                    }
                ],
                "eq_spans": [],
                "section": "The Influence of \u03bb",
                "sec_num": "3.5"
            },
            {
                "text": "We compare our methods with GE-FL on all the 9 datasets in this section. Instead of using features obtained by information gain, we use LDA to select labeled features. Unlike information gain, LDA does not employ any instance labels to find labeled features. In this setting, we can build classification models without any instance annotation, but just with labeled features.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Using LDA Selected Features",
                "sec_num": "3.6"
            },
            {
                "text": "Table 1 shows that our three methods significantly outperform GE-FL. Incorporating neutral features performs better than GE-FL on 7 of the 9 datasets, maximum entropy is better on 8 datasets, and KL divergence better on 7 datasets.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 6,
                        "end": 7,
                        "text": "1",
                        "ref_id": "TABREF0"
                    }
                ],
                "eq_spans": [],
                "section": "Using LDA Selected Features",
                "sec_num": "3.6"
            },
            {
                "text": "LDA selects out the most predictive features as labeled features without considering the balance among classes. GE-FL does not exert any control on such an issue, so the performance is severely suffered. Our methods introduce auxiliary regularization terms to control such a bias problem and thus promote the model significantly.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Using LDA Selected Features",
                "sec_num": "3.6"
            },
            {
                "text": "There have been much work that incorporate prior knowledge into learning, and two related lines are surveyed here. One is to use prior knowledge to label unlabeled instances and then apply a standard learning algorithm. The other is to constrain the model directly with prior knowledge. Liu et al.(2004) manually labeled features which are highly predictive to unsupervised clustering assignments and use them to label unlabeled data. Chang et al.(2007) proposed constraint driven learning. They first used constraints and the learned model to annotate unlabeled instances, and then updated the model with the newly labeled data. Daum\u00e9 (2008) proposed a self training method in which several models are trained on the same dataset, and only unlabeled instances that satisfy the cross task knowledge constraints are used in the self training process. MaCallum et al.(2007) proposed generalized expectation(GE) criteria which formalised the knowledge as constraint terms about the expectation of the model into the objective function. Grac \u00b8a et al.(2007) proposed posterior regularization(PR) framework which projects the model's posterior onto a set of distributions that satisfy the auxiliary constraints. Druck et al.(2008) explored constraints of labeled features in the framework of GE by forcing the model's predicted feature distribution to approach the reference distribution. Andrzejewski et al.(2011) proposed a framework in which general domain knowledge can be easily incorporated into LDA. Altendorf et al.(2012) explored monotonicity constraints to improve the accuracy while learning from sparse data. Chen et al.(2013) tried to learn compre-hensible topic models by leveraging multi-domain knowledge. Mann and McCallum (2007; 2010) incorporated not only labeled features but also other knowledge like class distribution into the objective function of GE-FL. But they discussed only from the semisupervised perspective and did not investigate into the robustness problem, unlike what we addressed in this paper.",
                "cite_spans": [
                    {
                        "start": 287,
                        "end": 303,
                        "text": "Liu et al.(2004)",
                        "ref_id": null
                    },
                    {
                        "start": 435,
                        "end": 453,
                        "text": "Chang et al.(2007)",
                        "ref_id": null
                    },
                    {
                        "start": 630,
                        "end": 642,
                        "text": "Daum\u00e9 (2008)",
                        "ref_id": "BIBREF11"
                    },
                    {
                        "start": 850,
                        "end": 871,
                        "text": "MaCallum et al.(2007)",
                        "ref_id": null
                    },
                    {
                        "start": 1033,
                        "end": 1053,
                        "text": "Grac \u00b8a et al.(2007)",
                        "ref_id": null
                    },
                    {
                        "start": 1207,
                        "end": 1225,
                        "text": "Druck et al.(2008)",
                        "ref_id": null
                    },
                    {
                        "start": 1384,
                        "end": 1409,
                        "text": "Andrzejewski et al.(2011)",
                        "ref_id": null
                    },
                    {
                        "start": 1502,
                        "end": 1524,
                        "text": "Altendorf et al.(2012)",
                        "ref_id": null
                    },
                    {
                        "start": 1616,
                        "end": 1633,
                        "text": "Chen et al.(2013)",
                        "ref_id": null
                    },
                    {
                        "start": 1716,
                        "end": 1740,
                        "text": "Mann and McCallum (2007;",
                        "ref_id": "BIBREF23"
                    },
                    {
                        "start": 1741,
                        "end": 1746,
                        "text": "2010)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "4"
            },
            {
                "text": "There are also some active learning methods trying to use prior knowledge. Raghavan et al.(2006) proposed to use feedback on instances and features interlacedly, and demonstrated that feedback on features boosts the model much. Druck et al.(2009) proposed an active learning method which solicits labels on features rather than on instances and then used GE-FL to train the model.",
                "cite_spans": [
                    {
                        "start": 75,
                        "end": 96,
                        "text": "Raghavan et al.(2006)",
                        "ref_id": null
                    },
                    {
                        "start": 228,
                        "end": 246,
                        "text": "Druck et al.(2009)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "4"
            },
            {
                "text": "This paper investigates into the problem of how to leverage prior knowledge robustly in learning models. We propose three regularization terms on top of generalized expectation criteria. As demonstrated by the experimental results, the performance can be considerably improved when taking into account these factors. Comparative results show that our proposed methods is more effective and works more robustly against baselines. To the best of our knowledge, this is the first work to address the robustness problem of leveraging knowledge, and may inspire other research.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion and Discussions",
                "sec_num": "5"
            },
            {
                "text": "We then present more detailed discussions about the three regularization methods. Incorporating neutral features is the simplest way of regularization, which doesn't require any modification of GE-FL but just finding out some common features. But as Figure 1 (a) shows, only using neutral features are not strong enough to handle extremely unbalanced labeled features.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 257,
                        "end": 258,
                        "text": "1",
                        "ref_id": "FIGREF0"
                    }
                ],
                "eq_spans": [],
                "section": "Conclusion and Discussions",
                "sec_num": "5"
            },
            {
                "text": "The maximum entropy regularization term shows the strong ability of controlling unbalance.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion and Discussions",
                "sec_num": "5"
            },
            {
                "text": "This method doesn't need any extra knowledge, and is thus suitable when we know nothing about the corpus. But this method assumes that the categories are uniformly distributed, which may not be the case in practice, and it will have a degraded performance if the assumption is violated (see Figure 1 The KL divergence performs much better on unbalanced corpora than other methods. The reason is that KL divergence utilizes the reference class distribution and doesn't make any assumptions. The fact suggests that additional knowledge does benefit the model.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 298,
                        "end": 299,
                        "text": "1",
                        "ref_id": "FIGREF0"
                    }
                ],
                "eq_spans": [],
                "section": "Conclusion and Discussions",
                "sec_num": "5"
            },
            {
                "text": "However, the KL divergence term requires providing the true class distribution. Sometimes, we may have the exact knowledge about the true distribution, but sometimes we may not. Fortunately, the model is insensitive to the true distribution and therefore a rough estimation of the true distribution is sufficient. In our experiments, when the true class distribution is 1:2, where the reference class distribution is set to 1:1.5/1:2/1:2.5, the accuracy is 0.755/0.756/0.760 respectively. This provides us the possibility to perform simple computing on the corpus to obtain the distribution in reality. Or, we can set the distribution roughly with domain expertise.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion and Discussions",
                "sec_num": "5"
            },
            {
                "text": "Previous work shows the model is insensitive to the setting of the reference distribution.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            }
        ],
        "back_matter": [],
        "bib_entries": {
            "BIBREF1": {
                "ref_id": "b1",
                "title": "Learning from sparse data by exploiting monotonicity constraints",
                "authors": [
                    {
                        "first": "Eric",
                        "middle": [
                            "E"
                        ],
                        "last": "Altendorf",
                        "suffix": ""
                    },
                    {
                        "first": "Angelo",
                        "middle": [
                            "C"
                        ],
                        "last": "Restificar",
                        "suffix": ""
                    },
                    {
                        "first": "Thomas",
                        "middle": [
                            "G"
                        ],
                        "last": "Dietterich",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:1207.1364"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Eric E Altendorf, Angelo C Resti- ficar, and Thomas G Dietterich. 2012. Learning from sparse data by exploiting monotonicity constraints. arXiv preprint arXiv:1207.1364.",
                "links": null
            },
            "BIBREF2": {
                "ref_id": "b2",
                "title": "Latent dirichlet allocation with topic-in-set knowledge",
                "authors": [
                    {
                        "first": "Zhu",
                        "middle": [],
                        "last": "Andrzejewski",
                        "suffix": ""
                    },
                    {
                        "first": "David",
                        "middle": [],
                        "last": "Andrzejewski",
                        "suffix": ""
                    },
                    {
                        "first": "Xiaojin",
                        "middle": [],
                        "last": "Zhu",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "Proceedings of the NAACL HLT 2009 Workshop on Semi-Supervised Learning for Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "43--48",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Andrzejewski and Zhu2009] David Andrzejewski and Xiaojin Zhu. 2009. Latent dirichlet allocation with topic-in-set knowledge. In Proceedings of the NAACL HLT 2009 Workshop on Semi-Supervised Learning for Natural Language Processing, pages 43-48. Associa- tion for Computational Linguistics.",
                "links": null
            },
            "BIBREF4": {
                "ref_id": "b4",
                "title": "A framework for incorporating general domain knowledge into latent dirichlet allocation using first-order logic",
                "authors": [
                    {
                        "first": "David",
                        "middle": [],
                        "last": "Andrzejewski",
                        "suffix": ""
                    },
                    {
                        "first": "Xiaojin",
                        "middle": [],
                        "last": "Zhu",
                        "suffix": ""
                    },
                    {
                        "first": "Mark",
                        "middle": [],
                        "last": "Craven",
                        "suffix": ""
                    },
                    {
                        "first": "Benjamin",
                        "middle": [],
                        "last": "Recht",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "IJCAI Proceedings-International Joint Conference on Artificial Intelligence",
                "volume": "22",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "David Andrzejewski, Xiaojin Zhu, Mark Craven, and Benjamin Recht. 2011. A framework for incorporating general domain knowl- edge into latent dirichlet allocation using first-order logic. In IJCAI Proceedings-International Joint Con- ference on Artificial Intelligence, volume 22, page 1171.",
                "links": null
            },
            "BIBREF6": {
                "ref_id": "b6",
                "title": "Latent dirichlet allocation",
                "authors": [
                    {
                        "first": "Andrew",
                        "middle": [
                            "Y"
                        ],
                        "last": "David M Blei",
                        "suffix": ""
                    },
                    {
                        "first": "Michael",
                        "middle": [
                            "I"
                        ],
                        "last": "Ng",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Jordan",
                        "suffix": ""
                    }
                ],
                "year": 2003,
                "venue": "the Journal of machine Learning research",
                "volume": "3",
                "issue": "",
                "pages": "993--1022",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "David M Blei, Andrew Y Ng, and Michael I Jordan. 2003. Latent dirichlet allocation. the Journal of machine Learning research, 3:993- 1022.",
                "links": null
            },
            "BIBREF8": {
                "ref_id": "b8",
                "title": "Guiding semi-supervision with constraint-driven learning",
                "authors": [
                    {
                        "first": "Ming-Wei",
                        "middle": [],
                        "last": "Chang",
                        "suffix": ""
                    },
                    {
                        "first": "Lev",
                        "middle": [],
                        "last": "Ratinov",
                        "suffix": ""
                    },
                    {
                        "first": "Dan",
                        "middle": [],
                        "last": "Roth",
                        "suffix": ""
                    }
                ],
                "year": 2007,
                "venue": "ANNUAL MEETING-ASSOCIATION FOR COMPUTATIONAL LINGUIS-TICS",
                "volume": "45",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Ming-Wei Chang, Lev Ratinov, and Dan Roth. 2007. Guiding semi-supervision with constraint-driven learning. In ANNUAL MEETING- ASSOCIATION FOR COMPUTATIONAL LINGUIS- TICS, volume 45, page 280. Citeseer.",
                "links": null
            },
            "BIBREF10": {
                "ref_id": "b10",
                "title": "Leveraging multi-domain prior knowledge in topic models",
                "authors": [
                    {
                        "first": "Zhiyuan",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Arjun",
                        "middle": [],
                        "last": "Mukherjee",
                        "suffix": ""
                    },
                    {
                        "first": "Bing",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Meichun",
                        "middle": [],
                        "last": "Hsu",
                        "suffix": ""
                    },
                    {
                        "first": "Malu",
                        "middle": [],
                        "last": "Castellanos",
                        "suffix": ""
                    },
                    {
                        "first": "Riddhiman",
                        "middle": [],
                        "last": "Ghosh",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "Proceedings of the Twenty-Third international joint conference on Artificial Intelligence",
                "volume": "",
                "issue": "",
                "pages": "2071--2077",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Zhiyuan Chen, Arjun Mukherjee, Bing Liu, Meichun Hsu, Malu Castellanos, and Riddhiman Ghosh. 2013. Leveraging multi-domain prior knowl- edge in topic models. In Proceedings of the Twenty- Third international joint conference on Artificial Intel- ligence, pages 2071-2077. AAAI Press.",
                "links": null
            },
            "BIBREF11": {
                "ref_id": "b11",
                "title": "Cross-task knowledge-constrained self training",
                "authors": [
                    {
                        "first": "Hal",
                        "middle": [],
                        "last": "Iii",
                        "suffix": ""
                    },
                    {
                        "first": "Iii",
                        "middle": [],
                        "last": "Daum\u00e9",
                        "suffix": ""
                    }
                ],
                "year": 2008,
                "venue": "Proceedings of the conference on empirical methods in natural language processing",
                "volume": "",
                "issue": "",
                "pages": "680--688",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "III2008] Hal Daum\u00e9 III. 2008. Cross-task knowledge-constrained self training. In Proceedings of the conference on empirical methods in natural language processing, pages 680-688. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF13": {
                "ref_id": "b13",
                "title": "Learning from labeled features using generalized expectation criteria",
                "authors": [
                    {
                        "first": "Gregory",
                        "middle": [],
                        "last": "Druck",
                        "suffix": ""
                    },
                    {
                        "first": "Gideon",
                        "middle": [],
                        "last": "Mann",
                        "suffix": ""
                    },
                    {
                        "first": "Andrew",
                        "middle": [],
                        "last": "Mccallum",
                        "suffix": ""
                    }
                ],
                "year": 2008,
                "venue": "Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval",
                "volume": "",
                "issue": "",
                "pages": "595--602",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Gregory Druck, Gideon Mann, and Andrew McCallum. 2008. Learning from labeled fea- tures using generalized expectation criteria. In Pro- ceedings of the 31st annual international ACM SIGIR conference on Research and development in informa- tion retrieval, pages 595-602. ACM.",
                "links": null
            },
            "BIBREF15": {
                "ref_id": "b15",
                "title": "Active learning by labeling features",
                "authors": [
                    {
                        "first": "Gregory",
                        "middle": [],
                        "last": "Druck",
                        "suffix": ""
                    },
                    {
                        "first": "Burr",
                        "middle": [],
                        "last": "Settles",
                        "suffix": ""
                    },
                    {
                        "first": "Andrew",
                        "middle": [],
                        "last": "Mccallum",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing",
                "volume": "1",
                "issue": "",
                "pages": "81--90",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Gregory Druck, Burr Settles, and An- drew McCallum. 2009. Active learning by label- ing features. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Process- ing: Volume 1-Volume 1, pages 81-90. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF17": {
                "ref_id": "b17",
                "title": "Expectation maximization and posterior constraints",
                "authors": [
                    {
                        "first": "Joao V Grac",
                        "middle": [],
                        "last": "\u00b8a",
                        "suffix": ""
                    },
                    {
                        "first": "Kuzman",
                        "middle": [],
                        "last": "Ganchev",
                        "suffix": ""
                    },
                    {
                        "first": "Ben",
                        "middle": [],
                        "last": "Taskar",
                        "suffix": ""
                    }
                ],
                "year": 2007,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Joao V Grac \u00b8a, Kuzman Ganchev, and Ben Taskar. 2007. Expectation maximization and pos- terior constraints.",
                "links": null
            },
            "BIBREF18": {
                "ref_id": "b18",
                "title": "Prototype-driven learning for sequence models",
                "authors": [
                    {
                        "first": "Klein ; ] Aria",
                        "middle": [],
                        "last": "Haghighi",
                        "suffix": ""
                    },
                    {
                        "first": "Dan",
                        "middle": [],
                        "last": "Haghighi",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Klein",
                        "suffix": ""
                    }
                ],
                "year": 2006,
                "venue": "Proceedings of the main conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "320--327",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Haghighi and Klein2006] Aria Haghighi and Dan Klein. 2006. Prototype-driven learning for sequence models. In Proceedings of the main conference on Human Lan- guage Technology Conference of the North American Chapter of the Association of Computational Linguis- tics, pages 320-327. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF20": {
                "ref_id": "b20",
                "title": "Sentiment analysis with global topics and local dependency",
                "authors": [
                    {
                        "first": "Fangtao",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Minlie",
                        "middle": [],
                        "last": "Huang",
                        "suffix": ""
                    },
                    {
                        "first": "Xiaoyan",
                        "middle": [],
                        "last": "Zhu",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "AAAI",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Fangtao Li, Minlie Huang, and Xiaoyan Zhu. 2010. Sentiment analysis with global topics and local dependency. In AAAI.",
                "links": null
            },
            "BIBREF22": {
                "ref_id": "b22",
                "title": "Text classification by labeling words",
                "authors": [
                    {
                        "first": "Bing",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Xiaoli",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Wee",
                        "middle": [],
                        "last": "Sun Lee",
                        "suffix": ""
                    },
                    {
                        "first": "Philip",
                        "middle": [
                            "S"
                        ],
                        "last": "Yu",
                        "suffix": ""
                    }
                ],
                "year": 2004,
                "venue": "AAAI",
                "volume": "4",
                "issue": "",
                "pages": "425--430",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Bing Liu, Xiaoli Li, Wee Sun Lee, and Philip S Yu. 2004. Text classification by labeling words. In AAAI, volume 4, pages 425-430.",
                "links": null
            },
            "BIBREF23": {
                "ref_id": "b23",
                "title": "Simple, robust, scalable semisupervised learning via expectation regularization",
                "authors": [
                    {
                        "first": "Mccallum",
                        "middle": [],
                        "last": "Mann",
                        "suffix": ""
                    },
                    {
                        "first": "Gideon",
                        "middle": [
                            "S"
                        ],
                        "last": "Mann",
                        "suffix": ""
                    },
                    {
                        "first": "Andrew",
                        "middle": [],
                        "last": "Mccallum",
                        "suffix": ""
                    }
                ],
                "year": 2007,
                "venue": "Proceedings of the 24th international conference on Machine learning",
                "volume": "",
                "issue": "",
                "pages": "593--600",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Mann and McCallum2007] Gideon S Mann and Andrew McCallum. 2007. Simple, robust, scalable semi- supervised learning via expectation regularization. In Proceedings of the 24th international conference on Machine learning, pages 593-600. ACM.",
                "links": null
            },
            "BIBREF24": {
                "ref_id": "b24",
                "title": "Generalized expectation criteria for semi-supervised learning with weakly labeled data",
                "authors": [
                    {
                        "first": "Mccallum",
                        "middle": [],
                        "last": "Mann",
                        "suffix": ""
                    },
                    {
                        "first": "Gideon",
                        "middle": [
                            "S"
                        ],
                        "last": "Mann",
                        "suffix": ""
                    },
                    {
                        "first": "Andrew",
                        "middle": [],
                        "last": "Mccallum",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "The Journal of Machine Learning Research",
                "volume": "11",
                "issue": "",
                "pages": "955--984",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Mann and McCallum2010] Gideon S Mann and Andrew McCallum. 2010. Generalized expectation criteria for semi-supervised learning with weakly labeled data. The Journal of Machine Learning Research, 11:955- 984.",
                "links": null
            },
            "BIBREF26": {
                "ref_id": "b26",
                "title": "Generalized expectation criteria",
                "authors": [
                    {
                        "first": "Andrew",
                        "middle": [],
                        "last": "Mccallum",
                        "suffix": ""
                    },
                    {
                        "first": "Gideon",
                        "middle": [],
                        "last": "Mann",
                        "suffix": ""
                    },
                    {
                        "first": "Gregory",
                        "middle": [],
                        "last": "Druck",
                        "suffix": ""
                    }
                ],
                "year": 2007,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Andrew McCallum, Gideon Mann, and Gregory Druck. 2007. Generalized expectation criteria. Computer science technical note, University of Massachusetts, Amherst, MA.",
                "links": null
            },
            "BIBREF27": {
                "ref_id": "b27",
                "title": "An interactive algorithm for asking and incorporating feature feedback into support vector machines",
                "authors": [
                    {
                        "first": "Allan",
                        "middle": [
                            ";"
                        ],
                        "last": "Raghavan",
                        "suffix": ""
                    },
                    {
                        "first": "Hema",
                        "middle": [],
                        "last": "Raghavan",
                        "suffix": ""
                    },
                    {
                        "first": "James",
                        "middle": [],
                        "last": "Allan",
                        "suffix": ""
                    }
                ],
                "year": 2007,
                "venue": "Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval",
                "volume": "",
                "issue": "",
                "pages": "79--86",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Raghavan and Allan2007] Hema Raghavan and James Allan. 2007. An interactive algorithm for asking and incorporating feature feedback into support vector ma- chines. In Proceedings of the 30th annual interna- tional ACM SIGIR conference on Research and devel- opment in information retrieval, pages 79-86. ACM.",
                "links": null
            },
            "BIBREF29": {
                "ref_id": "b29",
                "title": "Active learning with feedback on features and instances",
                "authors": [
                    {
                        "first": "Omid",
                        "middle": [],
                        "last": "Hema Raghavan",
                        "suffix": ""
                    },
                    {
                        "first": "Rosie",
                        "middle": [],
                        "last": "Madani",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Jones",
                        "suffix": ""
                    }
                ],
                "year": 2006,
                "venue": "The Journal of Machine Learning Research",
                "volume": "7",
                "issue": "",
                "pages": "1655--1686",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Hema Raghavan, Omid Madani, and Rosie Jones. 2006. Active learning with feed- back on features and instances. The Journal of Ma- chine Learning Research, 7:1655-1686.",
                "links": null
            },
            "BIBREF31": {
                "ref_id": "b31",
                "title": "Incorporating prior knowledge into boosting",
                "authors": [
                    {
                        "first": "Marie",
                        "middle": [],
                        "last": "Robert E Schapire",
                        "suffix": ""
                    },
                    {
                        "first": "Mazin",
                        "middle": [],
                        "last": "Rochery",
                        "suffix": ""
                    },
                    {
                        "first": "Narendra",
                        "middle": [],
                        "last": "Rahim",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Gupta",
                        "suffix": ""
                    }
                ],
                "year": 2002,
                "venue": "ICML",
                "volume": "2",
                "issue": "",
                "pages": "538--545",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Robert E Schapire, Marie Rochery, Mazin Rahim, and Narendra Gupta. 2002. Incorpo- rating prior knowledge into boosting. In ICML, vol- ume 2, pages 538-545.",
                "links": null
            }
        },
        "ref_entries": {
            "FIGREF0": {
                "uris": null,
                "fig_num": "1",
                "num": null,
                "text": "Figure 1: Performance with unbalanced labeled features, tested on the movie dataset. Randomly select from the feature pool t (x-axis) labeled features for one class, and select 1 feature for the other. The unbalanced datasets in (b) are constructed by randomly removing 75% of the positive documents.",
                "type_str": "figure"
            },
            "FIGREF1": {
                "uris": null,
                "fig_num": "2",
                "num": null,
                "text": "Figure 2: Performance with balanced labeled features, tested on the movie dataset. Randomly select from the feature pool t (x-axis) labeled features for each class. The unbalanced datasets in (b) are constructed by randomly removing 75% of the positive documents.",
                "type_str": "figure"
            },
            "FIGREF2": {
                "uris": null,
                "fig_num": null,
                "num": null,
                "text": "Similar to (a), but the class distribution is unbalanced, by randomly removing 75% positive documents (positive:negative=1:4).",
                "type_str": "figure"
            },
            "FIGREF3": {
                "uris": null,
                "fig_num": "3",
                "num": null,
                "text": "Figure 3: Influence of unbalanced class distribution, tested on the movie dataset. We provide 10 labeled features for each class in (a), and, 10 for one class and 1 for the other in (b). The three unbalanced datasets are constructed by randomly removing 50%, 67%, 75% documents of the positive class.",
                "type_str": "figure"
            },
            "FIGREF4": {
                "uris": null,
                "fig_num": "4",
                "num": null,
                "text": "Figure 4: The influence of \u03bb, tested on the movie dataset. Randomly select from the feature pool t (x-axis) labeled features for one class, and keep 1 feature for the other. The unbalanced datasets in (b) are constructed by randomly removing 75% documents of the positive class.",
                "type_str": "figure"
            },
            "FIGREF5": {
                "uris": null,
                "fig_num": null,
                "num": null,
                "text": "(b), Figure 2(b), Figure 3(a)).",
                "type_str": "figure"
            },
            "TABREF0": {
                "content": "<table><tr><td>Dataset</td><td colspan=\"4\">GE-FL Neutral Features Max Entropy KL Divergence</td></tr><tr><td>movie</td><td>0.623</td><td>0.672</td><td>0.681</td><td>0.684</td></tr><tr><td>sraa</td><td>0.559</td><td>0.628</td><td>0.618</td><td>0.547</td></tr><tr><td>webkb</td><td>0.615</td><td>0.685</td><td>0.640</td><td>0.646</td></tr><tr><td>med-space</td><td>0.927</td><td>0.921</td><td>0.936</td><td>0.928</td></tr><tr><td>ibm-mac</td><td>0.817</td><td>0.796</td><td>0.837</td><td>0.833</td></tr><tr><td>baseball-hockey</td><td>0.915</td><td>0.935</td><td>0.925</td><td>0.923</td></tr><tr><td>20 newsgroups</td><td>0.667</td><td>0.669</td><td>0.680</td><td>0.677</td></tr><tr><td colspan=\"2\">financial-healthcare 0.588</td><td>0.618</td><td>0.618</td><td>0.507</td></tr><tr><td>sector.top</td><td>0.596</td><td>0.653</td><td>0.581</td><td>0.639</td></tr></table>",
                "num": null,
                "html": null,
                "text": "Performance using LDA-features. Bold text means the method performs better than GE-FL.",
                "type_str": "table"
            }
        }
    }
}